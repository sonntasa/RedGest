
@article{botvinick_conflict_2004,
	title = {Conflict monitoring and anterior cingulate cortex: an update},
	volume = {8},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661304002657},
	doi = {10.1016/j.tics.2004.10.003},
	shorttitle = {Conflict monitoring and anterior cingulate cortex},
	pages = {539--546},
	number = {12},
	journaltitle = {Trends in Cognitive Sciences},
	author = {Botvinick, Matthew M. and Cohen, Jonathan D. and Carter, Cameron S.},
	urldate = {2021-05-14},
	date = {2004-12},
	langid = {english},
	file = {Botvinick et al. - 2004 - Conflict monitoring and anterior cingulate cortex.pdf:/Users/sonntaghimself/Zotero/storage/ZYMWPLJP/Botvinick et al. - 2004 - Conflict monitoring and anterior cingulate cortex.pdf:application/pdf},
}

@article{botvinick_conflict_2001,
	title = {Conflict monitoring and cognitive control.},
	volume = {108},
	issn = {1939-1471, 0033-295X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.108.3.624},
	doi = {10.1037/0033-295X.108.3.624},
	pages = {624--652},
	number = {3},
	journaltitle = {Psychological Review},
	author = {Botvinick, Matthew M. and Braver, Todd S. and Barch, Deanna M. and Carter, Cameron S. and Cohen, Jonathan D.},
	urldate = {2021-05-14},
	date = {2001},
	langid = {english},
	file = {Botvinick et al. - 2001 - Conflict monitoring and cognitive control..pdf:/Users/sonntaghimself/Zotero/storage/48DRNVQQ/Botvinick et al. - 2001 - Conflict monitoring and cognitive control..pdf:application/pdf},
}

@article{eriksen_effects_1974,
	title = {Effects of noise letters upon the identification of a target letter in a nonsearch task},
	volume = {16},
	issn = {0031-5117, 1532-5962},
	url = {http://link.springer.com/10.3758/BF03203267},
	doi = {10.3758/BF03203267},
	pages = {143--149},
	number = {1},
	journaltitle = {Perception \& Psychophysics},
	author = {Eriksen, Barbara A. and Eriksen, Charles W.},
	urldate = {2021-05-14},
	date = {1974-01},
	langid = {english},
}

@article{simon_auditory_1967,
	title = {Auditory S-R compatibility: The effect of an irrelevant cue on information processing.},
	volume = {51},
	issn = {1939-1854, 0021-9010},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0020586},
	doi = {10.1037/h0020586},
	shorttitle = {Auditory S-R compatibility},
	pages = {300--304},
	number = {3},
	journaltitle = {Journal of Applied Psychology},
	author = {Simon, J. Richard and Rudell, Alan P.},
	urldate = {2021-05-14},
	date = {1967},
	langid = {english},
}

@article{stroop_studies_1935,
	title = {Studies of interference in serial verbal reactions.},
	volume = {18},
	issn = {0022-1015},
	url = {http://content.apa.org/journals/xge/18/6/643},
	doi = {10.1037/h0054651},
	pages = {643--662},
	number = {6},
	journaltitle = {Journal of Experimental Psychology},
	author = {Stroop, J. R.},
	urldate = {2021-05-14},
	date = {1935},
	langid = {english},
}

@article{de_jong_conditional_1994,
	title = {Conditional and unconditional automaticity: A dual-process model of effects of spatial stimulus-response correspondence.},
	volume = {20},
	issn = {1939-1277, 0096-1523},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0096-1523.20.4.731},
	doi = {10.1037/0096-1523.20.4.731},
	shorttitle = {Conditional and unconditional automaticity},
	pages = {731--750},
	number = {4},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {De Jong, Ritske and Liang, Chia-Chin and Lauber, Erick},
	urldate = {2021-05-14},
	date = {1994},
	langid = {english},
}

@article{dudschig_grounding_2023,
	title = {The grounding of logical operations: The role of color, shape, and emotional faces for 'yes' or 'no' decisions},
	volume = {49},
	issn = {0278-7393},
	url = {http://www.redi-bw.de/db/ebsco.php/search.ebscohost.com/login.aspx%3fdirect%3dtrue%26db%3dpsyh%26AN%3d2023-28029-001%26site%3dehost-live},
	doi = {10.1037/xlm0001181},
	shorttitle = {The grounding of logical operations},
	abstract = {Concerning the evolution of our mind, it is of core interest to understand how high-level cognitive functions are embedded within low-level cognitive functions. While the grounding of meaning units such as content words and sentence has been widely investigated, little is known about logical cognitive operations and their association with nonlinguistic cognition. However, recent theoretical claims have suggested that 'the foundations of logical oppositions and negation may well be much more deeply rooted in the physiological structure of human cognition than is standardly assumed' (p. 227, Jaspers, 2012). The present study investigated potential candidates for such a grounding process by exploring the associations between basic 'yes' versus 'no' decisions and nonlinguistic features. In five preregistered experiments investigating the interplay between deciding 'yes' or 'no' and color, shape, and facial expressions, there was converging evidence for the intercoupling between the process of performing a 'yes' (agreeing) or 'no' (rejecting) decision and emotional faces (happy/sad), color (green/red), and also shape (round/square and soft/sharp). Potential mechanisms for such associations are discussed. ({PsycInfo} Database Record (c) 2023 {APA}, all rights reserved)},
	pages = {477--492},
	number = {3},
	journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	shortjournal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {Dudschig, Carolin and Kaup, Barbara and Mackenzie, Ian Grant},
	urldate = {2024-08-05},
	date = {2023-03},
	note = {Publisher: American Psychological Association},
	keywords = {Color, Cognitive Ability, Decision Making, Emotions, negation, Facial Expressions, Facial Features, Form and Shape Perception, grounding, logical operators, Logical Thinking, polar decisions, yes-no},
	file = {EBSCO Full Text:/Users/sonntaghimself/Zotero/storage/7STP57X7/Dudschig et al. - 2023 - The grounding of logical operations The role of c.pdf:application/pdf},
}

@article{holle_role_2007,
	title = {The Role of Iconic Gestures in Speech Disambiguation: {ERP} Evidence},
	volume = {19},
	issn = {0898-929X, 1530-8898},
	url = {https://direct.mit.edu/jocn/article/19/7/1175/4402/The-Role-of-Iconic-Gestures-in-Speech},
	doi = {10.1162/jocn.2007.19.7.1175},
	shorttitle = {The Role of Iconic Gestures in Speech Disambiguation},
	abstract = {Abstract
            The present series of experiments explored the extent to which iconic gestures convey information not found in speech. Electroencephalogram ({EEG}) was recorded as participants watched videos of a person gesturing and speaking simultaneously. The experimental sentences contained an unbalanced homonym in the initial part of the sentence (e.g., She controlled the ball …) and were disambiguated at a target word in the subsequent clause (which during the game … vs. which during the dance …). Coincident with the initial part of the sentence, the speaker produced an iconic gesture which supported either the dominant or the subordinate meaning. Event-related potentials were time-locked to the onset of the target word. In Experiment 1, participants were explicitly asked to judge the congruency between the initial homonym-gesture combination and the subsequent target word. The N400 at target words was found to be smaller after a congruent gesture and larger after an incongruent gesture, suggesting that listeners can use gestural information to disambiguate speech. Experiment 2 replicated the results using a less explicit task, indicating that the disambiguating effect of gesture is somewhat task-independent. Unrelated grooming movements were added to the paradigm in Experiment 3. The N400 at subordinate targets was found to be smaller after subordinate gestures and larger after dominant gestures as well as grooming, indicating that an iconic gesture can facilitate the processing of a lesser frequent word meaning. The N400 at dominant targets no longer varied as a function of the preceding gesture in Experiment 3, suggesting that the addition of meaningless movements weakened the impact of gesture. Thus, the integration of gesture and speech in comprehension does not appear to be an obligatory process but is modulated by situational factors such as the amount of observed meaningful hand movements.},
	pages = {1175--1192},
	number = {7},
	journaltitle = {Journal of Cognitive Neuroscience},
	author = {Holle, Henning and Gunter, Thomas C.},
	urldate = {2024-09-16},
	date = {2007-07-01},
	langid = {english},
	file = {PDF:/Users/sonntaghimself/Zotero/storage/RMS5AU4Q/Holle and Gunter - 2007 - The Role of Iconic Gestures in Speech Disambiguation ERP Evidence.pdf:application/pdf},
}

@article{kelly_neural_2004,
	title = {Neural correlates of bimodal speech and gesture comprehension},
	volume = {89},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {0093934X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0093934X03003353},
	doi = {10.1016/S0093-934X(03)00335-3},
	abstract = {The present study examined the neural correlates of speech and hand gesture comprehension in a naturalistic context. Fifteen participants watched audiovisual segments of speech and gesture while event-related potentials ({ERPs}) were recorded to the speech. Gesture inﬂuenced the {ERPs} to the speech. Speciﬁcally, there was a right-lateralized N400 eﬀect—reﬂecting semantic integration—when gestures mismatched versus matched the speech. In addition, early sensory components in bilateral occipital and frontal sites diﬀerentiated speech accompanied by matching versus non-matching gestures. These results suggest that hand gestures may be integrated with speech at early and late stages of language processing.},
	pages = {253--260},
	number = {1},
	journaltitle = {Brain and Language},
	shortjournal = {Brain and Language},
	author = {Kelly, Spencer D. and Kravitz, Corinne and Hopkins, Michael},
	urldate = {2024-09-16},
	date = {2004-04},
	langid = {english},
	file = {PDF:/Users/sonntaghimself/Zotero/storage/REN5W78A/Kelly et al. - 2004 - Neural correlates of bimodal speech and gesture comprehension.pdf:application/pdf},
}

@article{kelly_integrating_2010,
	title = {Integrating Speech and Iconic Gestures in a Stroop-like Task: Evidence for Automatic Processing},
	volume = {22},
	issn = {0898-929X, 1530-8898},
	url = {https://direct.mit.edu/jocn/article/22/4/683/4833/Integrating-Speech-and-Iconic-Gestures-in-a-Stroop},
	doi = {10.1162/jocn.2009.21254},
	shorttitle = {Integrating Speech and Iconic Gestures in a Stroop-like Task},
	abstract = {Abstract
            Previous research has demonstrated a link between language and action in the brain. The present study investigates the strength of this neural relationship by focusing on a potential interface between the two systems: cospeech iconic gesture. Participants performed a Stroop-like task in which they watched videos of a man and a woman speaking and gesturing about common actions. The videos differed as to whether the gender of the speaker and gesturer was the same or different and whether the content of the speech and gesture was congruent or incongruent. The task was to identify whether a man or a woman produced the spoken portion of the videos while accuracy rates, {RTs}, and {ERPs} were recorded to the words. Although not relevant to the task, participants paid attention to the semantic relationship between the speech and the gesture, producing a larger N400 to words accompanied by incongruent versus congruent gestures. In addition, {RTs} were slower to incongruent versus congruent gesture–speech stimuli, but this effect was greater when the gender of the gesturer and speaker was the same versus different. These results suggest that the integration of gesture and speech during language comprehension is automatic but also under some degree of neurocognitive control.},
	pages = {683--694},
	number = {4},
	journaltitle = {Journal of Cognitive Neuroscience},
	author = {Kelly, Spencer D. and Creigh, Peter and Bartolotti, James},
	urldate = {2024-09-16},
	date = {2010-04-01},
	langid = {english},
	file = {PDF:/Users/sonntaghimself/Zotero/storage/RKNVD9BJ/Kelly et al. - 2010 - Integrating Speech and Iconic Gestures in a Stroop-like Task Evidence for Automatic Processing.pdf:application/pdf},
}

@article{kelly_two_2010,
	title = {Two Sides of the Same Coin: Speech and Gesture Mutually Interact to Enhance Comprehension},
	volume = {21},
	rights = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {0956-7976, 1467-9280},
	url = {https://journals.sagepub.com/doi/10.1177/0956797609357327},
	doi = {10.1177/0956797609357327},
	shorttitle = {Two Sides of the Same Coin},
	abstract = {Gesture and speech are assumed to form an integrated system during language production. Based on this view, we propose the integrated-systems hypothesis, which explains two ways in which gesture and speech are integrated—through mutual and obligatory interactions—in language comprehension. Experiment 1 presented participants with action primes (e.g., someone chopping vegetables) and bimodal speech and gesture targets. Participants related primes to targets more quickly and accurately when they contained congruent information (speech: “chop”; gesture: chop) than when they contained incongruent information (speech: “chop”; gesture: twist). Moreover, the strength of the incongruence affected processing, with fewer errors for weak incongruities (speech: “chop”; gesture: cut) than for strong incongruities (speech: “chop”; gesture: twist). Crucial for the integrated-systems hypothesis, this influence was bidirectional. Experiment 2 demonstrated that gesture’s influence on speech was obligatory. The results confirm the integrated-systems hypothesis and demonstrate that gesture and speech form an integrated system in language comprehension.},
	pages = {260--267},
	number = {2},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Kelly, Spencer D. and Özyürek, Aslı and Maris, Eric},
	urldate = {2024-09-16},
	date = {2010-02},
	langid = {english},
	file = {PDF:/Users/sonntaghimself/Zotero/storage/JBZ9SG9R/Kelly et al. - 2010 - Two Sides of the Same Coin Speech and Gesture Mutually Interact to Enhance Comprehension.pdf:application/pdf},
}

@article{ridderinkhof_micro-_2002,
	title = {Micro- and macro-adjustments of task set: activation and suppression in conflict tasks},
	volume = {66},
	issn = {0340-0727},
	url = {http://link.springer.com/10.1007/s00426-002-0104-7},
	doi = {10.1007/s00426-002-0104-7},
	shorttitle = {Micro- and macro-adjustments of task set},
	pages = {312--323},
	number = {4},
	journaltitle = {Psychological Research},
	shortjournal = {Psychological Research},
	author = {Ridderinkhof, Richard},
	urldate = {2022-09-28},
	date = {2002-11-01},
}
