
@incollection{stodden_knitr_2014,
	title = {knitr: A Comprehensive Tool for Reproducible Research in R},
	booktitle = {Implementing Reproducible Computational Research},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui},
	editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
	date = {2014},
}

@book{xie_dynamic_2015,
	location = {Boca Raton, Florida},
	edition = {2nd},
	title = {Dynamic Documents with R and knitr},
	url = {https://yihui.org/knitr/},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui},
	date = {2015},
}

@book{xie_knitr_2023,
	title = {knitr: A General-Purpose Package for Dynamic Report Generation in R},
	url = {https://yihui.org/knitr/},
	author = {Xie, Yihui},
	date = {2023},
}

@book{van_rossum_python_2009,
	location = {Scotts Valley, {CA}},
	title = {Python 3 Reference Manual},
	isbn = {1-4414-1269-7},
	publisher = {{CreateSpace}},
	author = {Van Rossum, Guido and Drake, Fred L.},
	date = {2009},
}

@book{mackenzie_psychreport_2022,
	title = {{psychReport}: Reproducible Reports in Psychology},
	url = {https://CRAN.R-project.org/package=psychReport},
	author = {Mackenzie, Ian G. and Dudschig, Carolin},
	date = {2022},
}

@book{lawrence_ez_2016,
	title = {ez: Easy Analysis and Visualization of Factorial Experiments},
	url = {https://CRAN.R-project.org/package=ez},
	author = {Lawrence, Michael A.},
	date = {2016},
}

@article{wickham_welcome_2019,
	title = {Welcome to the tidyverse},
	volume = {4},
	doi = {10.21105/joss.01686},
	pages = {1686},
	number = {43},
	journaltitle = {Journal of Open Source Software},
	author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and {McGowan}, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
	date = {2019},
}

@book{r_core_team_r_2021,
	location = {Vienna, Austria},
	title = {R: A Language and Environment for Statistical Computing},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	date = {2021},
}

@article{nolan_faster_2010,
	title = {{FASTER}: Fully Automated Statistical Thresholding for {EEG} artifact Rejection},
	volume = {192},
	issn = {01650270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027010003894},
	doi = {10.1016/j.jneumeth.2010.07.015},
	shorttitle = {{FASTER}},
	abstract = {Semantic Scholar extracted view of "
 {FASTER}: Fully Automated Statistical Thresholding for {EEG} artifact Rejection" by H. Nolan et al.},
	pages = {152--162},
	number = {1},
	journaltitle = {Journal of Neuroscience Methods},
	shortjournal = {Journal of Neuroscience Methods},
	author = {Nolan, H. and Whelan, R. and Reilly, R.B.},
	urldate = {2023-03-30},
	date = {2010-09},
	langid = {english},
	file = {Submitted Version:/home/samuel/Zotero/storage/9G4CV3XW/Nolan et al. - 2010 - FASTER Fully Automated Statistical Thresholding f.pdf:application/pdf},
}

@article{bell_information-maximization_1995,
	title = {An Information-Maximization Approach to Blind Separation and Blind Deconvolution},
	volume = {7},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/7/6/1129-1159/5909},
	doi = {10.1162/neco.1995.7.6.1129},
	abstract = {We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in "blind" signal processing.},
	pages = {1129--1159},
	number = {6},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Bell, Anthony J. and Sejnowski, Terrence J.},
	urldate = {2023-03-30},
	date = {1995-11},
	langid = {english},
}

@article{makeig_blind_1997,
	title = {Blind separation of auditory event-related brain responses into independent components},
	volume = {94},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.94.20.10979},
	doi = {10.1073/pnas.94.20.10979},
	abstract = {Averaged event-related potential ({ERP}) data recorded from the human scalp reveal electroencephalographic ({EEG}) activity that is reliably time-locked and phase-locked to experimental events. We report here the application of a method based on information theory that decomposes one or more {ERPs} recorded at multiple scalp sensors into a sum of components with fixed scalp distributions and sparsely activated, maximally independent time courses. Independent component analysis ({ICA}) decomposes {ERP} data into a number of components equal to the number of sensors. The derived components have distinct but not necessarily orthogonal scalp projections. Unlike dipole-fitting methods, the algorithm does not model the locations of their generators in the head. Unlike methods that remove second-order correlations, such as principal component analysis ({PCA}), {ICA} also minimizes higher-order dependencies. Applied to detected—and undetected—target {ERPs} from an auditory vigilance experiment, the algorithm derived ten components that decomposed each of the major response peaks into one or more {ICA} components with relatively simple scalp distributions. Three of these components were active only when the subject detected the targets, three other components only when the target went undetected, and one in both cases. Three additional components accounted for the steady-state brain response to a 39-Hz background click train. Major features of the decomposition proved robust across sessions and changes in sensor number and placement. This method of {ERP} analysis can be used to compare responses from multiple stimuli, task conditions, and subject states.},
	pages = {10979--10984},
	number = {20},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Makeig, Scott and Jung, Tzyy-Ping and Bell, Anthony J. and Ghahremani, Dara and Sejnowski, Terrence J.},
	urldate = {2023-03-30},
	date = {1997-09-30},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:/home/samuel/Zotero/storage/4TZ4JQ8L/Makeig et al. - 1997 - Blind separation of auditory event-related brain r.pdf:application/pdf},
}

@article{oostenveld_fieldtrip_2011,
	title = {{FieldTrip}: Open source software for advanced analysis of {MEG}, {EEG}, and invasive electrophysiological data},
	volume = {2011},
	issn = {1687-5273},
	doi = {10.1155/2011/156869},
	shorttitle = {{FieldTrip}},
	abstract = {This paper describes {FieldTrip}, an open source software package that we developed for the analysis of {MEG}, {EEG}, and other electrophysiological data. The software is implemented as a {MATLAB} toolbox and includes a complete set of consistent and user-friendly high-level functions that allow experimental neuroscientists to analyze experimental data. It includes algorithms for simple and advanced analysis, such as time-frequency analysis using multitapers, source reconstruction using dipoles, distributed sources and beamformers, connectivity analysis, and nonparametric statistical permutation tests at the channel and source level. The implementation as toolbox allows the user to perform elaborate and structured analyses of large data sets using the {MATLAB} command line and batch scripting. Furthermore, users and developers can easily extend the functionality and implement new algorithms. The modular design facilitates the reuse in other software packages.},
	pages = {156869},
	journaltitle = {Computational Intelligence and Neuroscience},
	shortjournal = {Comput Intell Neurosci},
	author = {Oostenveld, Robert and Fries, Pascal and Maris, Eric and Schoffelen, Jan-Mathijs},
	date = {2011},
	pmid = {21253357},
	pmcid = {PMC3021840},
	keywords = {Humans, Electroencephalography, Electrophysiological Phenomena, Magnetoencephalography, Numerical Analysis, Computer-Assisted, Software, User-Computer Interface},
	file = {Full Text:/home/samuel/Zotero/storage/R37Z9QYI/Oostenveld et al. - 2011 - FieldTrip Open source software for advanced analy.pdf:application/pdf},
}

@article{delorme_eeglab_2004,
	title = {{EEGLAB}: an open source toolbox for analysis of single-trial {EEG} dynamics including independent component analysis},
	volume = {134},
	issn = {01650270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027003003479},
	doi = {10.1016/j.jneumeth.2003.10.009},
	shorttitle = {{EEGLAB}},
	abstract = {We have developed a toolbox and graphic user interface, {EEGLAB}, running under the cross-platform {MATLAB} environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged {EEG} data of any number of channels. Available functions include {EEG} data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial {ERP}-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), Independent Component Analysis ({ICA}) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. {EEGLAB} functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use {MATLAB} syntax. Menu options allow users to tune the behavior of {EEGLAB} to available memory. Middle-layer functions allow users to customize data processing using command history and interactive ‘pop’ functions. Experienced {MATLAB} users can use {EEGLAB} data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A ‘plug-in’ facility allows easy incorporation of new {EEG} modules into the main menu. {EEGLAB} is freely available (http://www.sccn.ucsd.edu/eeglab/) under the {GNU} public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.},
	pages = {9--21},
	number = {1},
	journaltitle = {Journal of Neuroscience Methods},
	shortjournal = {Journal of Neuroscience Methods},
	author = {Delorme, Arnaud and Makeig, Scott},
	urldate = {2023-03-30},
	date = {2004-03},
	langid = {english},
	file = {Delorme and Makeig - 2004 - EEGLAB an open source toolbox for analysis of sin.pdf:/home/samuel/Zotero/storage/V5FPZPL2/Delorme and Makeig - 2004 - EEGLAB an open source toolbox for analysis of sin.pdf:application/pdf},
}

@article{mackenzie_dmcfun_2021,
	title = {{DMCfun}: An R package for fitting Diffusion Model of Conflict ({DMC}) to reaction time and error rate data},
	volume = {5},
	issn = {25902601},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S259026012100031X},
	doi = {10.1016/j.metip.2021.100074},
	shorttitle = {{DMCfun}},
	pages = {100074},
	journaltitle = {Methods in Psychology},
	shortjournal = {Methods in Psychology},
	author = {Mackenzie, Ian G. and Dudschig, Carolin},
	urldate = {2022-10-07},
	date = {2021-12},
	langid = {english},
	file = {Full Text:/home/samuel/Zotero/storage/UTWWE3LE/Mackenzie and Dudschig - 2021 - DMCfun An R package for fitting Diffusion Model o.pdf:application/pdf},
}

@article{mittelstadt_electrophysiological_2022,
	title = {Electrophysiological evidence against parallel motor processing during multitasking},
	volume = {59},
	issn = {0048-5772, 1469-8986},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/psyp.13951},
	doi = {10.1111/psyp.13951},
	abstract = {We combined behavioral measures with electrophysiological measures of motor activation (i.e., lateralized readiness potentials, {LRPs}) to disentangle the relative contribution of premotor and motor processes to multitasking interference in the prioritized processing paradigm. Specifically, we presented stimuli of two tasks (primary and background task) in each trial, but participants were instructed to perform the background task only if the primary task required no response. As expected, task performance was substantially influenced by a task probability manipulation: Background task responses were faster, psychological refractory period effects were smaller, and interference from the second task (i.e., backward compatibility effects) was larger when there was a larger probability that this task required a response. Critically, stimulus-­locked and response-­locked {LRP} analyses indicate that these behavioral effects of parallel processing were not driven by background task motor processing (e.g., motoric response activation) taking place during primary task processing. Instead, the {LRP} results suggest that these effects were exclusively localized during premotor stages of processing (e.g., response selection). Thus, the present results generally provide evidence for multitasking accounts allowing parallel task processing during response selection, whereas the task-­specific motor responses are activated in a serial manner. One plausible account is that multiple task information sources can be processed in parallel, with sharing of limited cognitive resources depending on task relevance, but a primary and still active task goal prevents motor activation related to the goals of other tasks in order to avoid outcome conflict.},
	pages = {e13951},
	number = {1},
	journaltitle = {Psychophysiology},
	shortjournal = {Psychophysiology},
	author = {Mittelstädt, Victor and Mackenzie, Ian Grant and Leuthold, Hartmut and Miller, Jeff},
	urldate = {2024-05-02},
	date = {2022-01},
	langid = {english},
	file = {Mittelstädt et al. - 2022 - Electrophysiological evidence against parallel mot.pdf:/home/samuel/Zotero/storage/EPSSI8YJ/Mittelstädt et al. - 2022 - Electrophysiological evidence against parallel mot.pdf:application/pdf},
}

@article{barr_random_2013,
	title = {Random effects structure for confirmatory hypothesis testing: Keep it maximal},
	volume = {68},
	issn = {0749596X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X12001180},
	doi = {10.1016/j.jml.2012.11.001},
	shorttitle = {Random effects structure for confirmatory hypothesis testing},
	abstract = {Linear mixed-effects models ({LMEMs}) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using {LMEMs} for conﬁrmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that {LMEMs} generalize best when they include the maximal random effects structure justiﬁed by the design. The generalization performance of {LMEMs} including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only {LMEMs} used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal {LMEMs} should be the ‘gold standard’ for conﬁrmatory hypothesis testing in psycholinguistics and beyond.},
	pages = {255--278},
	number = {3},
	journaltitle = {Journal of Memory and Language},
	shortjournal = {Journal of Memory and Language},
	author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
	urldate = {2024-05-10},
	date = {2013-04},
	langid = {english},
	file = {Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf:/home/samuel/Zotero/storage/R9SHMPY4/Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf:application/pdf},
}

@misc{bates_parsimonious_2018,
	title = {Parsimonious Mixed Models},
	url = {http://arxiv.org/abs/1506.04967},
	abstract = {The analysis of experimental data with mixed-effects models requires decisions about the speciﬁcation of the appropriate random-effects structure. Recently, Barr, Levy, Scheepers, and Tily 2013 recommended ﬁtting ‘maximal’ models with all possible random effect components included. Estimation of maximal models, however, may not converge. We show that failure to converge typically is not due to a suboptimal estimation algorithm, but is a consequence of attempting to ﬁt a model that is too complex to be properly supported by the data, irrespective of whether estimation is based on maximum likelihood or on Bayesian hierarchical modeling with uninformative or weakly informative priors. Importantly, even under convergence, overparameterization may lead to uninterpretable models. We provide diagnostic tools for detecting overparameterization and guiding model simpliﬁcation.},
	number = {{arXiv}:1506.04967},
	publisher = {{arXiv}},
	author = {Bates, Douglas and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald},
	urldate = {2024-05-10},
	date = {2018-05-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1506.04967 [stat]},
	keywords = {Statistics - Methodology},
	file = {Bates et al. - 2018 - Parsimonious Mixed Models.pdf:/home/samuel/Zotero/storage/4E6N7CJ4/Bates et al. - 2018 - Parsimonious Mixed Models.pdf:application/pdf},
}

@article{peirce_psychopy2_2019,
	title = {{PsychoPy}2: Experiments in behavior made easy},
	volume = {51},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-018-01193-y},
	doi = {10.3758/s13428-018-01193-y},
	shorttitle = {{PsychoPy}2},
	abstract = {{PsychoPy} is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch {PsychoPy} every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
	pages = {195--203},
	number = {1},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and {MacAskill}, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	urldate = {2024-04-06},
	date = {2019-02-01},
	langid = {english},
	keywords = {Software, Psychology, Experiment, Open science, Open-source, Reaction time, Timing},
	file = {Full Text PDF:/home/samuel/Zotero/storage/W6MFVHTW/Peirce et al. - 2019 - PsychoPy2 Experiments in behavior made easy.pdf:application/pdf},
}

@article{erdfelder_efficiency_2021,
	title = {On the efficiency of the independent segments procedure: A direct comparison with sequential probability ratio tests.},
	volume = {26},
	issn = {1939-1463, 1082-989X},
	url = {https://doi.apa.org/doi/10.1037/met0000404},
	doi = {10.1037/met0000404},
	shorttitle = {On the efficiency of the independent segments procedure},
	abstract = {In this comment, we report a simulation study that assesses error rates and average sample sizes required to reach a statistical decision for two sequential procedures, the sequential probability ratio test ({SPRT}) originally proposed by Wald (1947) and the independent segments procedure ({ISP}) recently suggested by Miller and Ulrich (2020). Following Miller and Ulrich (2020), we use sequential one-tailed t tests as examples. In line with the optimal efﬁciency properties of the {SPRT} already proven by Wald and Wolfowitz (1948), the {SPRT} outperformed the {ISP} in terms of efﬁciency without compromising error probability control. The efﬁciency gain in terms of sample size reduction achieved with the {SPRT} t test relative to the {ISP} may be as high as 25\%. We thus recommend the {SPRT} as a default sequential testing procedure especially for detecting small or medium hypothesized effect sizes under H1 whenever a priori knowledge of the maximum sample size is not crucial. If a priori control of the maximum sample size is mandatory, however, the {ISP} is a very useful addition to the sequential testing literature.},
	pages = {501--506},
	number = {4},
	journaltitle = {Psychological Methods},
	shortjournal = {Psychological Methods},
	author = {Erdfelder, Edgar and Schnuerch, Martin},
	urldate = {2024-09-18},
	date = {2021-08},
	langid = {english},
	file = {PDF:/home/samuel/Zotero/storage/V8FARWEB/Erdfelder and Schnuerch - 2021 - On the efficiency of the independent segments procedure A direct comparison with sequential probabi.pdf:application/pdf},
}

@article{lakens_invited_2021,
	title = {Invited commentary: Comparing the independent segments procedure with group sequential designs.},
	volume = {26},
	issn = {1939-1463, 1082-989X},
	url = {https://doi.apa.org/doi/10.1037/met0000400},
	doi = {10.1037/met0000400},
	shorttitle = {Invited commentary},
	abstract = {Psychological science would become more efficient if researchers implemented sequential designs where feasible. Miller and Ulrich (2020) propose an independent segments procedure where data can be analyzed at a prespecified number of equally spaced looks while controlling the Type 1 error rate. Such procedures already exist in the sequential analysis literature, and in this commentary I reflect on whether psychologist should choose to adopt these existing procedure instead. I believe limitations in the independent segments procedure make it relatively unattractive. Being forced to stop for futility based on a bound not chosen to control Type 2 errors, or reject a smallest effect size of interest in an equivalence test, limit the inferences one can make. Having to use a prespecified number of equally spaced looks is logistically inconvenient. And not having the flexibility to choose α and β spending functions limit the possibility to design efficient studies based on the goal and limitations of the researcher. Recent software packages such as rpact (Wassmer \& Pahlke, 2019) make sequential designs equally easy to perform as the independent segments procedure. While learning new statistical methods always takes time, I believe psychological scientists should start on a path that will not limit them in the flexibility and inferences their statistical procedure provides.},
	pages = {498--500},
	number = {4},
	journaltitle = {Psychological Methods},
	shortjournal = {Psychological Methods},
	author = {Lakens, Daniël},
	urldate = {2024-09-18},
	date = {2021-08},
	langid = {english},
	file = {PDF:/home/samuel/Zotero/storage/AKA8REMH/Lakens - 2021 - Invited commentary Comparing the independent segments procedure with group sequential designs..pdf:application/pdf},
}

@article{ulrich_alternative_2021,
	title = {Alternative sequential methods in statistical testing: A reply to Lakens (2021) and Erdfelder and Schnuerch (2021).},
	volume = {26},
	issn = {1939-1463, 1082-989X},
	url = {https://doi.apa.org/doi/10.1037/met0000420},
	doi = {10.1037/met0000420},
	shorttitle = {Alternative sequential methods in statistical testing},
	abstract = {We recently developed a simple and general sequential sampling method for testing null hypotheses, the independent segments procedure ({ISP}; Miller \& Ulrich, 2021). In this reply, we discuss the comments of Erdfelder and Schnuerch (2021) and Lakens (2021), who consider alternative methods such as the sequential probability ratio test ({SPRT}) and the group sequential design ({GSD}), respectively. We evaluate the pros and cons of these alternatives and conclude that the {ISP} does have several advantages over these other methods, especially for psychological research. All of these sequential methods can save research resources because smaller sample sizes are required compared to standard nonsequential methods, so it seems appropriate for researchers to choose from a variety of sequential methods based on the practical requirements of their research.},
	pages = {507--512},
	number = {4},
	journaltitle = {Psychological Methods},
	shortjournal = {Psychological Methods},
	author = {Ulrich, Rolf and Miller, Jeff},
	urldate = {2024-09-18},
	date = {2021-08},
	langid = {english},
	file = {PDF:/home/samuel/Zotero/storage/484TKM4U/Ulrich and Miller - 2021 - Alternative sequential methods in statistical testing A reply to Lakens (2021) and Erdfelder and Sc.pdf:application/pdf},
}

@article{miller_simple_2021,
	title = {A simple, general, and efficient method for sequential hypothesis testing: The independent segments procedure.},
	volume = {26},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000350},
	doi = {10.1037/met0000350},
	shorttitle = {A simple, general, and efficient method for sequential hypothesis testing},
	abstract = {We propose a new sequential hypothesis testing procedure in which data are collected and analyzed in a series of independent segments. As in fixed-sample hypothesis testing and in previous sequential procedures, the overall   level can be set to any desired value. Like other sequential procedures, the independent segments procedure generally requires smaller samples than fixed-sample procedures— often approximately 30\% smaller—to achieve the same   level and statistical power. Relative to other sequential procedures, the new method has the advantages that it is simpler to use, requires fewer assumptions, and can be used with a wider array of statistical tests. Thus, in some circumstances the independent segments procedure may provide an attractive option for increasing the efficiency of statistical testing.},
	pages = {486--497},
	number = {4},
	journaltitle = {Psychological Methods},
	shortjournal = {Psychological Methods},
	author = {Miller, Jeff and Ulrich, Rolf},
	urldate = {2024-09-18},
	date = {2021-08},
	langid = {english},
	file = {PDF:/home/samuel/Zotero/storage/AI95VNU4/Miller and Ulrich - 2021 - A simple, general, and efficient method for sequential hypothesis testing The independent segments.pdf:application/pdf},
}

@article{van_doorn_jasp_2021,
	title = {The {JASP} guidelines for conducting and reporting a Bayesian analysis},
	volume = {28},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-020-01798-5},
	doi = {10.3758/s13423-020-01798-5},
	abstract = {Despite the increasing popularity of Bayesian inference in empirical research, few practical guidelines provide detailed recommendations for how to apply Bayesian procedures and interpret the results. Here we offer specific guidelines for four different stages of Bayesian statistical reasoning in a research setting: planning the analysis, executing the analysis, interpreting the results, and reporting the results. The guidelines for each stage are illustrated with a running example. Although the guidelines are geared towards analyses performed with the open-source statistical software {JASP}, most guidelines extend to Bayesian inference in general.},
	pages = {813--826},
	number = {3},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychon Bull Rev},
	author = {van Doorn, Johnny and van den Bergh, Don and Böhm, Udo and Dablander, Fabian and Derks, Koen and Draws, Tim and Etz, Alexander and Evans, Nathan J. and Gronau, Quentin F. and Haaf, Julia M. and Hinne, Max and Kucharský, Šimon and Ly, Alexander and Marsman, Maarten and Matzke, Dora and Gupta, Akash R. Komarlu Narendra and Sarafoglou, Alexandra and Stefan, Angelika and Voelkel, Jan G. and Wagenmakers, Eric-Jan},
	urldate = {2024-09-20},
	date = {2021-06-01},
	langid = {english},
	keywords = {Bayesian inference, Scientific reporting, Statistical software},
	file = {Full Text PDF:/home/samuel/Zotero/storage/43RJ2JX3/van Doorn et al. - 2021 - The JASP guidelines for conducting and reporting a Bayesian analysis.pdf:application/pdf},
}

@article{matzke_effect_2015,
	title = {The effect of horizontal eye movements on free recall: A preregistered adversarial collaboration.},
	volume = {144},
	issn = {1939-2222, 0096-3445},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000038},
	doi = {10.1037/xge0000038},
	shorttitle = {The effect of horizontal eye movements on free recall},
	abstract = {A growing body of research has suggested that horizontal saccadic eye movements facilitate the retrieval of episodic memories in free recall and recognition memory tasks. Nevertheless, a minority of studies have failed to replicate this effect. This article attempts to resolve the inconsistent results by introducing a novel variant of proponent-skeptic collaboration. The proposed approach combines the features of adversarial collaboration and purely confirmatory preregistered research. Prior to data collection, the adversaries reached consensus on an optimal research design, formulated their expectations, and agreed to submit the findings to an academic journal regardless of the outcome. To increase transparency and secure the purely confirmatory nature of the investigation, the 2 parties set up a publicly available adversarial collaboration agreement that detailed the proposed design and all foreseeable aspects of the data analysis. As anticipated by the skeptics, a series of Bayesian hypothesis tests indicated that horizontal eye movements did not improve free recall performance. The skeptics suggested that the nonreplication may partly reflect the use of suboptimal and questionable research practices in earlier eye movement studies. The proponents countered this suggestion and used a p curve analysis to argue that the effect of horizontal eye movements on explicit memory did not merely reflect selective reporting.},
	pages = {e1--e15},
	number = {1},
	journaltitle = {Journal of Experimental Psychology: General},
	shortjournal = {Journal of Experimental Psychology: General},
	author = {Matzke, Dora and Nieuwenhuis, Sander and Van Rijn, Hedderik and Slagter, Heleen A. and Van Der Molen, Maurits W. and Wagenmakers, Eric-Jan},
	urldate = {2024-09-20},
	date = {2015-02},
	langid = {english},
	file = {PDF:/home/samuel/Zotero/storage/LDGSLSS8/Matzke et al. - 2015 - The effect of horizontal eye movements on free recall A preregistered adversarial collaboration..pdf:application/pdf},
}

@article{royall_probability_2000,
	title = {On the Probability of Observing Misleading Statistical Evidence},
	volume = {95},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474264},
	doi = {10.1080/01621459.2000.10474264},
	abstract = {The law of likelihood explains how to interpret statistical data as evidence. Specifically, it gives to the discipline of statistics a precise and objective measure of the strength of statistical evidence supporting one probability distribution vis-à-vis another. That measure is the likelihood ratio. But evidence, even when properly interpreted, can be misleading—observations can truly constitute strong evidence supporting one distribution when the other is true. What makes statistical evidence valuable to science is that this cannot occur very often. Here we examine two bounds on the probability of observing strong misleading evidence. One is a universal bound, applicable to every pair of probability distributions. The other bound, much smaller, applies to all pairs of distributions within fixed-dimensional parametric models in large samples. The second bound comes from examining how the probability of strong misleading evidence varies as a function of the alternative value of the parameter. We show that in large samples one curve describes how this probability first rises and then falls as the alternative moves away from the true parameter value for a very wide class of models. We also show that this large-sample curve, and the bound that its maximum value represents, applies to profile likelihood ratios for one-dimensional parameters in fixed-dimensional parametric models, but does not apply to the estimated likelihood ratios that result from replacing the nuisance parameters by their global maximum likelihood estimates.},
	pages = {760--768},
	number = {451},
	journaltitle = {Journal of the American Statistical Association},
	author = {Royall, Richard},
	urldate = {2024-09-20},
	date = {2000-09-01},
	note = {Publisher: {ASA} Website
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.2000.10474264},
	file = {Full Text PDF:/home/samuel/Zotero/storage/RHRQKJ29/Royall - 2000 - On the Probability of Observing Misleading Statistical Evidence.pdf:application/pdf},
}

@article{lakens_simulation-based_2021,
	title = {Simulation-Based Power Analysis for Factorial Analysis of Variance Designs},
	volume = {4},
	issn = {2515-2459, 2515-2467},
	url = {http://journals.sagepub.com/doi/10.1177/2515245920951503},
	doi = {10.1177/2515245920951503},
	abstract = {Researchers often rely on analysis of variance ({ANOVA}) when they report results of experiments. To ensure that a study is adequately powered to yield informative results with an {ANOVA}, researchers can perform an a priori power analysis. However, power analysis for factorial {ANOVA} designs is often a challenge. Current software solutions do not allow power analyses for complex designs with several within-participants factors. Moreover, power analyses often need [Formula: see text] or Cohen’s f as input, but these effect sizes are not intuitive and do not generalize to different experimental designs. We have created the R package Superpower and online Shiny apps to enable researchers without extensive programming experience to perform simulation-based power analysis for {ANOVA} designs of up to three within- or between-participants factors. Predicted effects are entered by specifying means, standard deviations, and, for within-participants factors, the correlations. The simulation provides the statistical power for all {ANOVA} main effects, interactions, and individual comparisons. The software can plot power across a range of sample sizes, can control for multiple comparisons, and can compute power when the homogeneity or sphericity assumption is violated. This Tutorial demonstrates how to perform a priori power analysis to design informative studies for main effects, interactions, and individual comparisons and highlights important factors that determine the statistical power for factorial {ANOVA} designs.},
	pages = {251524592095150},
	number = {1},
	journaltitle = {Advances in Methods and Practices in Psychological Science},
	shortjournal = {Advances in Methods and Practices in Psychological Science},
	author = {Lakens, Daniël and Caldwell, Aaron R.},
	urldate = {2024-09-24},
	date = {2021-01},
	langid = {english},
	file = {Full Text:/home/samuel/Zotero/storage/FMM6L7M8/Lakens and Caldwell - 2021 - Simulation-Based Power Analysis for Factorial Analysis of Variance Designs.pdf:application/pdf},
}
